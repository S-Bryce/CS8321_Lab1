{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RUBRIC\n",
    "\n",
    "[2 Points] Present an overview for what type of bias you will be investigating and why the particular investigation you will be doing is relevant. You might consider asking questions like: Why is it important to find this kind of bias in machine learning models? Why will the type of investigation I am performing be relevant to other researchers or practitioners? \n",
    "\n",
    "[2 Points] Present one or more research questions that you will be answering and explain the methods that you will employ to answer these research questions. Present a hypothesis as part of your research questions. \n",
    "\n",
    "[2 Points] As part of your assignment, you will choose a methodology that involves comparing two (or more) techniques to one another. Discuss how you will measure a difference between the two techniques. That is, if you are measuring the difference statistically, what test will you use and why is it appropriate? Are there any limitations to performing this test that you should be aware of? \n",
    "\n",
    "[4 Points] Carryout your analysis and model training. Explain your steps in as much detail so that the instructor can understand your code. \n",
    "\n",
    "[4 Points] Present results from your analysis and provide evidence from the results that support or refute your hypothesis. Write a conclusion based upon the various analyses you performed. Be sure to reference your research questions systematically in your conclusion. With your analysis complete, are there any additional research questions or limitations to your conclusions?\n",
    "\n",
    "[1 Points] Identify two conferences or journals that would be interested in the results of your analysis.  \n",
    "If using code from another author (not your own), you will be graded on the clarity of explanatory comments you add to the code. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from types import FunctionType\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchtext\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# BASE_PATH: str = os.path.dirname(os.path.abspath(__file__))\n",
    "BASE_PATH: str = \"/home/paperspace/Desktop/8321-Mach-Lrng-Neural-Ntwrks/Lab1/CS8321_Lab1\" # REPLACE THIS LINE FOR YOUR LOCAL\n",
    "\n",
    "CLASSIFIERS_PATH: str = BASE_PATH + \"/classifiers/\"\n",
    "DATASET_PATH: str = BASE_PATH + \"/datasets/\"\n",
    "EMBEDDINGS_PATH: str = BASE_PATH + \"/embeddings/\"\n",
    "NUM_EMOTIONS: int = 28\n",
    "EMBED_SIZE: int = 0\n",
    "\n",
    "# Check if our key directories exist\n",
    "if not os.path.exists(CLASSIFIERS_PATH):\n",
    "    raise FileNotFoundError(\"Could not find folder for classifier models.\")\n",
    "if not os.path.exists(DATASET_PATH):\n",
    "    raise FileNotFoundError(\"Could not find folder with GoEmotion dataset.\")\n",
    "if not os.path.exists(EMBEDDINGS_PATH):\n",
    "    raise FileNotFoundError(\"Could not find folder with word embeddings sets.\")\n",
    "\n",
    "# Is the cuda GPU available?\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"Warning: Using CPU for Pytorch.\")\n",
    "device: device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's define our basic BDRNN architecture\n",
    "class BDRNN(torch.nn.Module):\n",
    "    def __init__(self, vocab_word_count: int, vectors: torch.Tensor, output_size: int, num_layers: int, dropout: float,\n",
    "                 *args: tuple[any],\n",
    "                 **kwargs: dict[str, any]) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.num_layers = num_layers if num_layers > 1 else 2\n",
    "        self.hidden_size = NUM_EMOTIONS // num_layers\n",
    "\n",
    "        self.embeddings = torch.nn.Embedding.from_pretrained(vectors, padding_idx=EMBED_SIZE)\n",
    "\n",
    "        self.rnn_layers = torch.nn.RNN(input_size=vocab_word_count, hidden_size=self.hidden_size, num_layers=num_layers,\n",
    "                                       bidirectional=True, dropout=dropout, batch_first=True)\n",
    "\n",
    "        self.output_layer = torch.nn.Linear(self.hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input_data) -> torch.Tensor:\n",
    "        embedded: torch.Tensor = self.embeddings(input_data)\n",
    "\n",
    "        output: torch.Tensor\n",
    "        hidden: torch.Tensor\n",
    "        output, hidden = self.rnn_layers(embedded)\n",
    "\n",
    "        return self.output_layer(hidden[-1, :])\n",
    "\n",
    "\n",
    "class pandas_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df: pd.DataFrame) -> None:\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index: int) -> (str, str):\n",
    "        return self.df[\"text\"].iloc[index], self.df[\"emotion_ids\"].iloc[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Deserialize the embeddings, and return word labels with their corresponding tensors.\"\"\"\n",
    "def get_vectors(embedding: str) -> tuple[dict[str, int], torch.Tensor]:\n",
    "    skip_first_line: bool = False\n",
    "    global EMBED_SIZE\n",
    "    match embedding:\n",
    "        case \"glove\":\n",
    "            embedding_path: str = EMBEDDINGS_PATH + \"glove.840B.300d.txt\"\n",
    "            EMBED_SIZE = 2196018\n",
    "            embedding_components: int = 300\n",
    "        case \"word2vec\":\n",
    "            embedding_path: str = EMBEDDINGS_PATH + \"GoogleNews-vectors-negative300.bin\"\n",
    "            gn_model = KeyedVectors.load_word2vec_format(embedding_path, binary=True)\n",
    "        case \"numberbatch\":\n",
    "            embedding_path: str = EMBEDDINGS_PATH + \"numberbatch-19.08-en.txt\"\n",
    "            EMBED_SIZE = 516782\n",
    "            embedding_components: int = 300\n",
    "            skip_first_line = True\n",
    "        case default:\n",
    "            raise RuntimeError(\"Invalid embedding chosen.\")\n",
    "        \n",
    "    # Deserializing glove and numberbatch embeddings\n",
    "    if not os.path.exists(embedding_path):\n",
    "        raise FileNotFoundError(\"Could not find embedding file: {}\".format(embedding_path))\n",
    "    with (open(embedding_path, encoding=\"utf_8\") as embeddings_file):\n",
    "        word_labels: dict[str, int] = {}\n",
    "        tensor: torch.Tensor = torch.empty((EMBED_SIZE + 1, embedding_components), dtype=torch.float32, device=device)\n",
    "        \n",
    "        # We need to skip the first line of the numberbatch embeddings because that's header information\n",
    "        if skip_first_line:\n",
    "            _ = embeddings_file.readline()\n",
    "        \n",
    "        # Clean up the file and load the embeddings into a tensor\n",
    "        for index, embedding in enumerate(embeddings_file):\n",
    "            embedding_split: list[str] = embedding.rstrip().split(\" \")\n",
    "            word_labels[embedding_split[0]] = index\n",
    "            tensor[index] = torch.tensor([float(val) for val in embedding_split[1:]], dtype=torch.float32,\n",
    "                                         device=device)\n",
    "            # Output our progress every 100,000 words\n",
    "            if (index + 1) % 100000 == 0:\n",
    "                print(\"Processed {}/{}\".format(index + 1, EMBED_SIZE))\n",
    "        tensor[-1] = torch.zeros(embedding_components, dtype=torch.float32, device=device)\n",
    "\n",
    "        # Adding a padding token\n",
    "        word_labels[\"<PAD>\"] = EMBED_SIZE\n",
    "        tensor.to(device)\n",
    "        return word_labels, tensor\n",
    "\n",
    "\"\"\" Tokenize the text and convert it into a list of integers. We'll use a dictionary to map words to integers. \n",
    "    We'll also use a special token (\"something\") for words that are not in the dictionary.\n",
    "    The tokenizer function splits the text into words.\"\"\"\n",
    "def tokenize(text: str, labels: dict, tokenizer: FunctionType) -> list[int]:\n",
    "    return [labels[word] if word in labels.keys() else labels[\"something\"] for word in tokenizer(text)]\n",
    "\n",
    "\n",
    "def resolve_emotions(id: str) -> str:\n",
    "    return [emotions[int(emotion)] for emotion in id.split(\",\")]\n",
    "\n",
    "\"\"\" \n",
    "Train a Bidirectional RNN model \n",
    "\"\"\"\n",
    "def train(model: BDRNN, batches, num_epochs: int):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "    criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "    losses = []\n",
    "\n",
    "    model.train()\n",
    "    for epoch_num, epochs in enumerate(range(num_epochs)):\n",
    "        correct: int = 0\n",
    "        total: int = 0\n",
    "        for num_batch, batch in enumerate(batches):\n",
    "            for sentence, emotions in batch:\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                predictions = model(sentence)\n",
    "                # Rounding is naive, we should base this off a confidence threshold\n",
    "                guesses = torch.round(torch.sigmoid(predictions))\n",
    "                if torch.equal(guesses, emotions): correct += 1\n",
    "                total += 1\n",
    "\n",
    "                loss = criterion(predictions, emotions)\n",
    "                losses.append(float(loss))\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    "                optimizer.step()\n",
    "        print(\"Epoch: {} | Loss: {} | Accuracy: {}%\".format(epoch_num + 1, sum(losses) / len(losses), (correct /\n",
    "                                                                                                      total) * 100))\n",
    "\n",
    "def collate(batch: list[tuple[list[int], list[str]]]) -> list[tuple[torch.IntTensor, torch.Tensor]]:\n",
    "    final_batch = []\n",
    "    max_tokens = len(max(batch, key=lambda tuple: len(tuple[0]))[0])\n",
    "    for sentence, emotions in batch:\n",
    "        sentence.extend([EMBED_SIZE] * (max_tokens - len(sentence)))\n",
    "        sentence = torch.IntTensor([int(value) for value in sentence]).to(device)\n",
    "        # There's definitely a way to do a list comprehension here but I'm too stupid to figure it out\n",
    "        _emotions = torch.zeros(NUM_EMOTIONS, dtype=torch.float32, device=device)\n",
    "        emotions = emotions.split(\",\")\n",
    "        for emotion in emotions:\n",
    "            _emotions[int(emotion)] = 1.0\n",
    "        final_batch.append((sentence, _emotions))\n",
    "    return final_batch  # Can we modify in-place instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text emotion_ids\n",
      "0  My favourite food is anything I didn't have to...          27\n",
      "1  Now if he does off himself, everyone will thin...          27\n",
      "2                     WHY THE FUCK IS BAYLESS ISOING           2\n",
      "3                        To make her feel threatened          14\n",
      "4                             Dirty Southern Wankers           3\n",
      "                                                text emotion_ids\n",
      "0  Iâ€™m really sorry about your situation :( Altho...          25\n",
      "1    It's wonderful because it's awful. At not with.           0\n",
      "2  Kings fan here, good luck to you guys! Will be...          13\n",
      "3  I didn't know that, thank you for teaching me ...          15\n",
      "4  They got bored from haunting earth for thousan...          27\n",
      "Processed 100000/516782\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Now we need to handle our dataset\n",
    "    with open(DATASET_PATH + \"emotions.txt\") as emotions_file:\n",
    "        emotions = [emotion.strip() for emotion in emotions_file]\n",
    "    if len(emotions) != NUM_EMOTIONS or emotions[4] != \"approval\":\n",
    "        raise RuntimeError(\"Failed to load emotion mappings.\")\n",
    "\n",
    "    training_set = pd.read_csv(DATASET_PATH + \"train.tsv\", delimiter=\"\\t\", names=[\"text\", \"emotion_ids\"],\n",
    "                               usecols=[0, 1])\n",
    "    testing_set = pd.read_csv(DATASET_PATH + \"test.tsv\", delimiter=\"\\t\", usecols=[0, 1])\n",
    "    print(training_set.head())\n",
    "    print(testing_set.head())\n",
    "\n",
    "    max_words: int = max(training_set[\"text\"].map(len).max(), testing_set[\"text\"].map(len).max())\n",
    "    input_dim: int = 2 ** math.ceil(math.log2(max_words)) if max_words >= 2 else 2\n",
    "\n",
    "    # Time to do some training!\n",
    "    labels, vectors = get_vectors(\"numberbatch\")\n",
    "    tokenizer = torchtext.data.utils.get_tokenizer(\"basic_english\")\n",
    "    training_set[\"text\"] = training_set[\"text\"].apply(tokenize, labels=labels, tokenizer=tokenizer)\n",
    "    testing_set[\"text\"] = testing_set[\"text\"].apply(tokenize, labels=labels, tokenizer=tokenizer)\n",
    "    print(training_set.head())\n",
    "    print(testing_set.head())\n",
    "    numberbatch_model = BDRNN(vectors.shape[1], vectors, NUM_EMOTIONS, 4, 0.5).to(device)\n",
    "    train_dataset = pandas_dataset(training_set)\n",
    "    test_dataset = pandas_dataset(testing_set)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=collate)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=True, collate_fn=collate)\n",
    "    print('Created `training dataloader` with %d batches!' % len(train_dataloader))\n",
    "    print('Created `testing dataloader` with %d batches!' % len(test_dataloader))\n",
    "    train(numberbatch_model, train_dataloader, 10)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download link for word2vec: https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing\n",
    "# Download link for Glove: https://huggingface.co/stanfordnlp/glove/resolve/main/glove.840B.300d.zip\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import ndarray\n",
    "from sklearn.manifold import TSNE\n",
    "from torch import Tensor, cat\n",
    "from torch.cuda import is_available as cuda_is_available\n",
    "from train import get_vectors\n",
    "\n",
    "\n",
    "# EDITABLE VARIABLES\n",
    "embeddings = [\"numberbatch\", \"glove\"] # Embeddings definition. Add word2vec once deserialization is done.\n",
    "\n",
    "# Word comparison groups. Format: [base_word, similar_word_1, similar_word_2]\n",
    "word_comparison_groups = [\n",
    "    [\"tire\", \"tired\", \"tyre\"],\n",
    "]\n",
    "\n",
    "# Add a new distance function here if you want.\n",
    "\"\"\"Calculate the distances between a base word and two similar words using Euclidean, Cosine, and Manhattan distances.\"\"\"\n",
    "def calculate_distances(base_word: ndarray[float], similar_word_1: ndarray[float], similar_word_2: ndarray[float]) -> dict[str, list[float]]:\n",
    "    return {\n",
    "        \"euclidean\": [euclidean_distance(similar_word_1, base_word), euclidean_distance(similar_word_2, base_word)],\n",
    "        \"cosine\": [cosine_similarity(similar_word_1, base_word), cosine_similarity(similar_word_2, base_word)],\n",
    "        \"manhattan\": [manhattan_distance(similar_word_1, base_word), manhattan_distance(similar_word_2, base_word)],\n",
    "    }\n",
    "\n",
    "# We should look at comparing vectors in different embeddings and see how well ambigious words center around common\n",
    "# synonyms for each meaning. We could probably do some sort of visualization for this as well.\n",
    "\n",
    "def euclidean_distance(vector1: Tensor, vector2: Tensor) -> float:\n",
    "    return np.linalg.norm(vector1 - vector2)\n",
    "\n",
    "def cosine_similarity(vector1: Tensor, vector2: Tensor) -> float:\n",
    "    return np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2))\n",
    "\n",
    "def manhattan_distance(v1, v2):\n",
    "    return np.sum(np.abs(v1 - v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Converts the given list of tensors to a numpy array based on GPU availability.\"\"\"\n",
    "def convert_tensors_to_numpy(embeddings_list: list[Tensor]) -> ndarray[float]:\n",
    "    if cuda_is_available():\n",
    "        numpy_vectors = np.array([vector.cpu().numpy() for vector in embeddings_list])\n",
    "    else:\n",
    "        numpy_vectors = np.array([vector.numpy() for vector in embeddings_list])\n",
    "    return numpy_vectors\n",
    "\n",
    "\"\"\"Returns the word vectors to compare from the given numpy vectors. These vectors are a word groups members\"\"\"\n",
    "def get_word_vectors_to_compare(numpy_vectors: ndarray[float]) -> tuple[ndarray[float], ndarray[float], ndarray[float]]:\n",
    "    return numpy_vectors[0], numpy_vectors[1], numpy_vectors[2]\n",
    "\n",
    "\"\"\"Returns a dictionary of distance types to their calculated distances for the given word vectors.\"\"\"\n",
    "def get_distances(embeddings_list: list[Tensor]) -> dict[str, list[float]]:\n",
    "    numpy_vectors = convert_tensors_to_numpy(embeddings_list)\n",
    "    base_word, similar_word1, similar_word2 = get_word_vectors_to_compare(numpy_vectors)\n",
    "    return calculate_distances(base_word, similar_word1, similar_word2)\n",
    "\n",
    "\"\"\"Returns a dictionary of embedding names to their respective word vectors and vocabularies\"\"\"\n",
    "def get_embeddings(embeddings: list[str]) -> dict[str, (dict[str, int], Tensor)]:\n",
    "    if len(embeddings) == 0:\n",
    "        raise ValueError(\"No embeddings were selected to load.\")\n",
    "    \n",
    "    result = {}\n",
    "    for embedding in embeddings:\n",
    "        vocab, vectors = get_vectors(embedding)\n",
    "        result[embedding] = (vocab, vectors)\n",
    "    return result\n",
    "\n",
    "\"\"\"Returns a dictionary of embedding names to a list of comparison groups, the words whose distances are being compared\"\"\"\n",
    "def get_comparison_embeddings(embeddings: dict[str, (dict[str, int], Tensor)]) -> dict[str, list[list[Tensor]]]:\n",
    "    # Dictionary of embedding name to list of comparison groups\n",
    "    result: dict[str, list[list[Tensor]]] = {}\n",
    "    for embed_name, (vocab, vectors) in embeddings.items():\n",
    "        comparisons = []\n",
    "        if embed_name not in result:\n",
    "            result[embed_name] = []\n",
    "        \n",
    "        # Populate the comparison groups\n",
    "        for idx, group in enumerate(word_comparison_groups):\n",
    "            comparisons = []\n",
    "            for word in group:\n",
    "                comparisons.append(vectors[vocab[word]])\n",
    "            result[embed_name].append(comparisons)\n",
    "    return result\n",
    "\n",
    "\"\"\"Returns a dictionary of embedding names to a list of dictionaries of distance types to their calculated distances\"\"\"\n",
    "def compare_embeddings(comparison_embeddings: dict[str, list[list[Tensor]]]) -> dict[str, list[dict[str, list[float]]]]:\n",
    "    result = {}\n",
    "    for embedding, word_groups in comparison_embeddings.items():\n",
    "        for idx, group_vectors in enumerate(word_groups):\n",
    "            if result.get(embedding) is None:\n",
    "                result[embedding] = []\n",
    "            distances: dict[str, list[float]] = get_distances(group_vectors)\n",
    "            result[embedding].append(distances)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"Plots boxplots of the distance ratios for each embedding and distance type.\"\"\"\n",
    "def compare_distances(embedding_distances: dict[str, list[dict[str, list[float]]]]):\n",
    "    \"\"\"Returns a dictionary of embedding names to a dictionary of distance types to their calculated distance ratios.\"\"\"\n",
    "    def calculate_distance_ratios():\n",
    "        # Dict of embedding name to distance type and all of that distance type's calculated distance ratios\n",
    "        ratios: dict[str, dict[str, list[float]]] = {}\n",
    "        # For every distance type for embeddings\n",
    "        for embedding_name, distances in embedding_distances.items():\n",
    "            ratios[embedding_name] = {}\n",
    "            for distance in distances:\n",
    "                for distance_type, values in distance.items():\n",
    "                    if ratios[embedding_name].get(distance_type) is None:\n",
    "                        ratios[embedding_name][distance_type] = []\n",
    "                    ratio = (max(values[0], values[1]) / min(values[0], values[1]))\n",
    "                    ratios[embedding_name][distance_type].append(ratio)\n",
    "        return ratios\n",
    "\n",
    "    \"\"\"\n",
    "    Plots boxplots of the distance ratios for each embedding and distance type.\n",
    "    Args: ratios: dict[str, dict[str, list[float]]] - Dictionary of embedding names to a dictionary of distance types to a list of all their calculated distance ratios.\n",
    "    \n",
    "    Ex:\n",
    "    ratios = {\n",
    "        \"glove\": {\n",
    "            \"euclidean\": [1.0, 2.55, 1.380, 4.44, 4.4, 4983],\n",
    "            \"cosine\": [1.0, 2.55, 1.380, 4.44, 4.4, 4983],\n",
    "            ...\n",
    "        },\n",
    "        \"numberbatch\": {\n",
    "            \"euclidean\": [1.0, 2.55, 1.380, 4.44, 4.4, 4983],\n",
    "            \"cosine\": [1.0, 2.55, 1.380, 4.44, 4.4, 4983],\n",
    "            ...        \n",
    "        }\n",
    "    }\n",
    "    \"\"\"\n",
    "    def show_boxplots(ratios: dict[str, dict[str, list[float]]]):\n",
    "        distances: list[dict[str, list[float]]] = list(ratios.values())\n",
    "        # Get all the values per distance type for every embedding\n",
    "        to_plot = {}\n",
    "        for i in range(0, len(distances)):\n",
    "            for embedding_name, distances2 in ratios.items():\n",
    "                for distance_type, values in distances2.items():\n",
    "                    print(embedding_name, distance_type, values)\n",
    "                    if to_plot.get(distance_type) is None:\n",
    "                        to_plot[distance_type] = {}\n",
    "                    to_plot[distance_type][embedding_name] = values\n",
    "        \n",
    "        # For every distance metric, plot boxplots for all embeddings\n",
    "        for distance_type, embedding_data in to_plot.items():\n",
    "            fig, axs = plt.subplots(figsize=(10, 8))\n",
    "            boxplots_data = []\n",
    "            labels = []\n",
    "            for embedding_name, values in embedding_data.items():\n",
    "                boxplots_data.append(values)\n",
    "                labels.append(embedding_name)\n",
    "            axs.boxplot(boxplots_data)\n",
    "            axs.set_xticklabels(labels)\n",
    "            axs.set_title(distance_type)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "    # Dict of embedding name to distance type and its calculated distance ratio\n",
    "    ratios = calculate_distance_ratios()\n",
    "    show_boxplots(ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_embeddings = get_embeddings(embeddings)\n",
    "comp_embeddings = get_comparison_embeddings(orig_embeddings)\n",
    "comp_distances = compare_embeddings(comp_embeddings)\n",
    "compare_distances(comp_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "remote-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
